{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multimodel.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPO+bacJjKO/Wi8mS6gQBTB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ian-byrne/MADSmilestone2/blob/main/multimodel1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WJ-YY1RBAgi"
      },
      "source": [
        "Multiple Model Option"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1FoRQ6XYh-E",
        "outputId": "989ed918-d8d7-4d13-982b-f23f8278e5f9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flfv_Cqa4at-",
        "outputId": "f7ba9d67-e6c1-46ab-a994-aa1bb357f19e"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/ian-byrne/MADSmilestone2.git\n",
        "# Change directory into cloned repo\n",
        "%cd MADSmilestone2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MADSmilestone2' already exists and is not an empty directory.\n",
            "/content/MADSmilestone2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ouIghrj2PN7",
        "outputId": "7a04f7ae-b399-4b20-cec6-46ce19a16318"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRCdqp64T5CV",
        "outputId": "81188566-1bf9-4c87-a819-a8fa20397c73"
      },
      "source": [
        "!pip install boto3"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.18.44)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.5.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.44 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.21.44)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.44->boto3) (1.26.6)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.44->boto3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.44->boto3) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyEMNGgmWTFo",
        "outputId": "ba7fa6ae-0678-425b-f69e-395bb5a0321b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data\t\t\t Labeling\t       README.md\n",
            "ian_testingground.ipynb  Loading\t       Supervised\n",
            "ImagePlayground\t\t Model_Datasets.ipynb  Supervised_CNN.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PogN9gqzcOEx",
        "outputId": "db0fba5e-a19f-4097-ef38-2d1ef593b986"
      },
      "source": [
        "# General Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "# Custom Libraries\n",
        "import Loading.load_data as ld\n",
        "\n",
        "# Pytroch Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "# To Evaluate model\n",
        "from tqdm import tqdm\n",
        "# import torchmetrics\n",
        "# from torchmetrics import ConfusionMatrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# To visualize model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from skimage.io import imread\n",
        "\n",
        "# To split the data\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcxL35AcBpHR"
      },
      "source": [
        "from botocore.exceptions import ClientError\n",
        "from torch.nn.modules.activation import ReLU\n",
        "# Set to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq2Fj5cGUvlm"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "# import from module later\n",
        "class ResizedClocks(Dataset):\n",
        "    #Resized clock drawing dataset\n",
        "\n",
        "    def __init__(self, round, round_labels):\n",
        "        \n",
        "       # Args:\n",
        "           # round (int): Round to grab images from. \n",
        "           # values (list of tuples): Corresponding values for the round.\n",
        "        \n",
        "        self.round = round\n",
        "        self.vals = round_labels\n",
        "        self.client = boto3.client('s3', \n",
        "                                    aws_access_key_id=pubkey, \n",
        "                                    aws_secret_access_key=seckey)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.vals)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        spid = self.vals[idx][0]\n",
        "        label = self.vals[idx][1]\n",
        "        bucket = \"clockimages\" #\"test-bucket-clockids-aicrowd\"\n",
        "        obj_name = f\"NHATS_R{self.round}_ClockDrawings/{spid}.tif\" #f\"{self.round}_{spid}.tif\"\n",
        "        #filename = str(spid)+\".tif\"\n",
        "        temp = tempfile.NamedTemporaryFile()\n",
        "\n",
        "        try:\n",
        "          client.download_file(bucket, obj_name, temp.name)\n",
        "\n",
        "          im = Image.open(temp.name)\n",
        "\n",
        "          gray = im.convert('1')\n",
        "          resized = gray.resize((160, 207)) \n",
        "          im_arr = np.array(resized).astype(int)\n",
        "\n",
        "          sample = {'image': im_arr, 'label': label}\n",
        "        \n",
        "          temp.close()\n",
        "\n",
        "          return sample\n",
        "          \n",
        "        except botocore.exceptions.ClientError as e:\n",
        "          #logging.error(e)\n",
        "          pass"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1JK1NXXV1DZ"
      },
      "source": [
        "file = open(\"Data/Dictionaries/score_dicts/tr_scor_dict_bal.txt\", \"r\")\n",
        "\n",
        "contents = file.read()\n",
        "im_scores = ast.literal_eval(contents)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAVQQwk8PrPG"
      },
      "source": [
        "#num_epochs = 20\n",
        "batch_size = 8\n",
        "learning_rate = .001\n",
        "kernel_size = 3\n",
        "stride = 1\n",
        "padding = 1 #2*floor(3/2)\n",
        "\n",
        "accuracy_stats = {\n",
        "    'train': [],\n",
        "    'val': []\n",
        "}\n",
        "\n",
        "loss_stats = {\n",
        "    'train': [],\n",
        "    'val': []\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNHnJYysXnqV",
        "outputId": "5ab2337c-74ef-45db-dd16-73e4b2c33e90"
      },
      "source": [
        "path = \"/content/gdrive/MyDrive/numpy_files/Score_data/\"\n",
        "training_data, y_train_tensor = ld.load_np_files(path+\"train_score_im.npy\", path+\"train_score_labels.npy\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23621, 1, 368, 284)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu8kAT744xRy",
        "outputId": "8ad5bcd1-cc23-415e-f0d0-3d5ed0c95c4f"
      },
      "source": [
        "validation_data, y_val_tensor = ld.load_np_files(path+\"val_score_im.npy\", path+\"val_score_labels.npy\")\n",
        "test_data, y_test_tensor = ld.load_np_files(path+\"tst_score_im.npy\", path+\"tst_score_labels.npy\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2544, 1, 368, 284)\n",
            "(2541, 1, 368, 284)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1cMZCzp9wK2"
      },
      "source": [
        "y_train_tensor = y_train_tensor.to(torch.long)\n",
        "y_test_tensor = y_test_tensor.to(torch.long)\n",
        "y_test_tensor = y_test_tensor.to(torch.long)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqI32aaA_0yU",
        "outputId": "a3296e3a-8ed5-4fc4-f508-2d7f9e515545"
      },
      "source": [
        "y_train_tensor.dtype"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjYDHApzc07a"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size = batch_size, shuffle = False) \n",
        "validate_loader = torch.utils.data.DataLoader(validation_data, batch_size = batch_size, shuffle = False)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = False)\n",
        "#Labels \n",
        "classes = (0, 1, 2, 3, 4, 5)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSbSa2U3Bo72"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    # without considering batch size: Input shape : (None,368, 284, 1) , parameters: (3*3*1*16+16) = 160\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 16, # one input channel gray scale, 16 filters out\n",
        "                            kernel_size = 3, stride = 1, padding = 1) #Out:(None,386, 284, 16)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) #params: (3*3*16*32+32) = 4640                        \n",
        "    self.pool1 = nn.MaxPool2d(2, 2) #Out: (None, 184, 142, 32)\n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) #params: (3*3*16*32+32) = 4640    \n",
        "    self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 64, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248                     \n",
        "    self.pool2 = nn.MaxPool2d(2, 2) #Output shape = (None, 92, 71, 64)\n",
        "    self.bn2 = nn.BatchNorm2d(64) \n",
        "\n",
        "    self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 128, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248 \n",
        "    self.conv6 = nn.Conv2d(in_channels = 128, out_channels = 128, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248\n",
        "    self.pool3 = nn.MaxPool2d(2, 2) #Output shape = (None, 46, 35, 128)\n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "    \n",
        "    # Fully connected layer\n",
        "    self.fc1 = nn.Linear(128*46*35,6)\n",
        "    #self.fc2 = nn.Linear(120, 60)\n",
        "    #self.fc3 = nn.Linear(60, 30)\n",
        "    #self.fc4 = nn.Linear(30, 3) # left with 3 for the three classes \n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn1(self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))))\n",
        "    x = self.bn2(self.pool2(F.relu(self.conv4(F.relu(self.conv3(x))))))\n",
        "    x = self.bn3(self.pool3(F.relu(self.conv6(F.relu(self.conv5(x))))))\n",
        "    x = x.view(x.size(0),128*46*35)\n",
        "    x = self.fc1(x)\n",
        "\n",
        "\n",
        "    return x "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRLTUIbpBoWQ"
      },
      "source": [
        "def accuracy(y_pred, y_test):\n",
        "  y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "  _, y_pred_prob = torch.max(y_pred_softmax, dim = 1)\n",
        "  \n",
        "  #y_preds = y_pred.argmax(dim=1)\n",
        "\n",
        "  correct_pred = (y_pred_prob == y_test).float()\n",
        "  #print(\"correct sum: \", correct_pred.sum())\n",
        "  #print('correct total length: ', len(correct_pred))\n",
        "  #print(correct_pred)\n",
        "  acc = correct_pred.sum() / len(correct_pred)\n",
        "  \n",
        "  #acc = correct_pred.sum().float() / float( y_test.size(0) )\n",
        "\n",
        "  acc = torch.round(acc * 100)\n",
        "\n",
        "  return acc"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvp-oYUuBozP",
        "outputId": "0c88581d-c4a5-4a0d-c66b-df76d1d0d8e3"
      },
      "source": [
        "# Create model object \n",
        "model = ConvNet()\n",
        "if torch.cuda.is_available():\n",
        "    model = model.to(float).cuda()\n",
        "    print('Model training on GPU')\n",
        "else:\n",
        "    print(\"CUDA is not available. Training on CPU...\")\n",
        "\n",
        "#for param in model.parameters():\n",
        "  #print(str(param.data.numpy().shape)+'\\n')\n",
        "  #print(\"weights fc1: \", model.fc1.weight)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "\n",
        "# Optimizer (can use SGD or ADAM)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)#, momentum = 0.9) #or ADAM/ momentum\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9) #or ADAM/ momentum\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training on GPU\n",
            "ConvNet(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=206080, out_features=6, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5qNtmj2Bop7"
      },
      "source": [
        "def train_val_model(epochs):\n",
        "  for epoch in range(1, epochs + 1):\n",
        "\n",
        "    # TRAINING ********************************\n",
        "    train_epoch_loss = 0\n",
        "    train_epoch_acc = 0\n",
        "\n",
        "    # set model in training mode (recommended)\n",
        "    model.train()\n",
        "\n",
        "    \n",
        "    # Double check\n",
        "    tr_run_loss=0\n",
        "    tr_correct=0\n",
        "    tr_total=0\n",
        "    train_accu = []\n",
        "    train_losses = []\n",
        "    \n",
        "    print('\\nEpoch$ : %d'%epoch)\n",
        "    for x_train_batch, y_train_batch in tqdm(train_loader):\n",
        "      x_train_batch = x_train_batch.to(float).to(device) # for GPU support\n",
        "      y_train_batch = y_train_batch.to(torch.long).to(device) \n",
        "\n",
        "      #print(x_train_batch.shape)\n",
        "\n",
        "      # sets gradients to 0 to prevent interference with previous epoch\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass through NN\n",
        "      y_train_pred = model(x_train_batch)#.to(float))\n",
        "      train_loss = criterion(y_train_pred, y_train_batch)\n",
        "      train_acc = accuracy(y_train_pred, y_train_batch)\n",
        "\n",
        "      # Backward pass, updating weights\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Statistics\n",
        "      train_epoch_loss += train_loss.item()\n",
        "      train_epoch_acc += train_acc.item()\n",
        "\n",
        "      # Double check scores\n",
        "      tr_run_loss += train_loss.item()\n",
        "     \n",
        "      _, predicted = y_train_pred.max(1)\n",
        "      tr_total += y_train_batch.size(0)\n",
        "      tr_correct += predicted.eq(y_train_batch).sum().item()\n",
        "       \n",
        "    tr_loss = tr_run_loss/len(train_loader)\n",
        "    accu = 100.*tr_correct/tr_total\n",
        "   \n",
        "    train_accu.append(accu)\n",
        "    train_losses.append(tr_loss)\n",
        "    print('Train Loss: %.3f | Train Accuracy: %.3f'%(tr_loss,accu))\n",
        "    # VALIDATION****************************************   \n",
        "    \n",
        "    with torch.set_grad_enabled(False):\n",
        "      val_epoch_loss = 0\n",
        "      val_epoch_acc = 0\n",
        "\n",
        "      # Double check\n",
        "      val_run_loss=0\n",
        "      val_correct=0\n",
        "      val_total=0\n",
        "      val_accu = []\n",
        "      val_losses = []\n",
        "\n",
        "\n",
        "      model.eval()\n",
        "      for x_val_batch, y_val_batch in validate_loader:\n",
        "      \n",
        "        x_val_batch =  x_val_batch.to(float).to(device)\n",
        "        y_val_batch = y_val_batch.to(torch.long).to(device)\n",
        "            \n",
        "        # Forward pass\n",
        "        y_val_pred = model(x_val_batch)   \n",
        "        val_loss = criterion(y_val_pred, y_val_batch)\n",
        "        val_acc = accuracy(y_val_pred, y_val_batch)\n",
        "            \n",
        "        val_epoch_loss += val_loss.item()\n",
        "        val_epoch_acc += val_acc.item()\n",
        "\n",
        "        # Double check\n",
        "        \n",
        "        val_run_loss += val_loss.item()\n",
        "     \n",
        "        _, predictedv = y_val_pred.max(1)\n",
        "        val_total += y_train_batch.size(0)\n",
        "        val_correct += predictedv.eq(y_val_batch).sum().item()\n",
        "       \n",
        "      vl_loss = val_run_loss/len(validate_loader)\n",
        "      accuv = 100.*val_correct/val_total\n",
        "   \n",
        "      val_accu.append(accuv)\n",
        "      val_losses.append(vl_loss)\n",
        "      print('Validation Loss: %.3f | Validation Accuracy: %.3f'%(vl_loss,accuv))\n",
        "\n",
        "\n",
        "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
        "    loss_stats['val'].append(val_epoch_loss/len(validate_loader))\n",
        "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
        "    accuracy_stats['val'].append(val_epoch_acc/len(validate_loader))\n",
        "                              \n",
        "    \n",
        "    print(f'Epoch {epoch+0:03}: Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(validate_loader):.5f}') \n",
        "    print(f'Train Acc: {train_epoch_acc/len(train_loader):.3f} | Val Acc: {val_epoch_acc/len(validate_loader):.3f}')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "PKoBD-EJIQL-",
        "outputId": "746a56c3-eb5e-4752-a2b5-365295d5cefe"
      },
      "source": [
        "train_val_model(20)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch$ : 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2953/2953 [04:05<00:00, 12.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 82025023494401968.000 | Train Accuracy: 90.356\n",
            "Validation Loss: 41388445545193805054077829120.000 | Validation Accuracy: 38.616\n",
            "Epoch 001: Train Loss: 82025023494401968.00000 | Val Loss: 41388445545193805054077829120.00000\n",
            "Train Acc: 90.357 | Val Acc: 24.101\n",
            "\n",
            "Epoch$ : 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2953/2953 [04:05<00:00, 12.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 7853103009110312484385849344.000 | Train Accuracy: 91.067\n",
            "Validation Loss: 8926887819846007304380326346752.000 | Validation Accuracy: 38.616\n",
            "Epoch 002: Train Loss: 7853103009110312484385849344.00000 | Val Loss: 8926887819846007304380326346752.00000\n",
            "Train Acc: 91.068 | Val Acc: 24.101\n",
            "\n",
            "Epoch$ : 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2953/2953 [04:04<00:00, 12.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1560312281610386833906722550776533614592.000 | Train Accuracy: 88.561\n",
            "Validation Loss: 667630177403319877759243114909198578614272.000 | Validation Accuracy: 38.616\n",
            "Epoch 003: Train Loss: 1560312281610386833906722550776533614592.00000 | Val Loss: 667630177403319877759243114909198578614272.00000\n",
            "Train Acc: 88.562 | Val Acc: 24.101\n",
            "\n",
            "Epoch$ : 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2953/2953 [04:05<00:00, 12.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 125898058266615370724531390959759868299056661921792.000 | Train Accuracy: 90.729\n",
            "Validation Loss: 138930532496926959838073540777244644256823133308190720.000 | Validation Accuracy: 38.616\n",
            "Epoch 004: Train Loss: 125898058266615370724531390959759868299056661921792.00000 | Val Loss: 138930532496926959838073540777244644256823133308190720.00000\n",
            "Train Acc: 90.730 | Val Acc: 24.101\n",
            "\n",
            "Epoch$ : 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 465/2953 [00:38<03:27, 12.02it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f8136c749d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_val_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-1b21b4e37156>\u001b[0m in \u001b[0;36mtrain_val_model\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0;31m# Statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       \u001b[0mtrain_epoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m       \u001b[0mtrain_epoch_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQIPgSt4IQE7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai0YQ-zcIP9M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIQ9i36NIPiV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}