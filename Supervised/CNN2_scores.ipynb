{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN2_scores.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ian-byrne/MADSmilestone2/blob/main/CNN2_scores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa6L-qwlfHPf"
      },
      "source": [
        "# Supervised Learning: Clock Drawing Image Classification with Convolutional Neural Networks\n",
        "### Stacey Beck and Ian Byrne\n",
        "\n",
        "- Split data into sets of Training (x = image arrays ; y = labels), Test (~10% image arrays), and Validation (~10% of the Training). \n",
        "- Build CNN using Pytorch for Training and Test:\n",
        "  - Specify CUDA\n",
        "  - 2D convolution, Normalization (for faster training), Non-linear Activation Function (ex. RELU), Max Pooling (downsampling to reduce learned parameters).\n",
        "  - Define Layers \n",
        "  - Build Forward and backward pass\n",
        "  - Define optimizer (due to many - deep - nodes) ex) ADAM\n",
        "  - Calculate Loss (BCE)\n",
        "  - Calculate Accuracy, Precision, Recall (Confusion Matrix)\n",
        "  - Plot ROC and print Confusion Matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKcEhDBuf5ow",
        "outputId": "1ab53108-4994-4e75-c813-36974d6424ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eoct7Or8ezZq",
        "outputId": "855c1819-d7d2-4d7a-be5b-daf0b52031c6"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/ian-byrne/MADSmilestone2.git\n",
        "# Change directory into cloned repo\n",
        "%cd MADSmilestone2\n",
        "#!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MADSmilestone2' already exists and is not an empty directory.\n",
            "/content/MADSmilestone2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Log111B8T-zg",
        "outputId": "8b3dc4e6-442b-414c-be6f-71f7d2f09a12"
      },
      "source": [
        "!pip install torchmetrics boto3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.18.47)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.9.0+cu102)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.10.0.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.47 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.21.47)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.5.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.47->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.47->boto3) (1.26.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.47->boto3) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (2.4.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtH9tfFdQepN",
        "outputId": "61f409a3-e78e-4415-a904-a3877800ba9a"
      },
      "source": [
        "# General Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import logging\n",
        "import os\n",
        "import boto3\n",
        "from botocore.exceptions import ClientError\n",
        "import requests\n",
        "import botocore\n",
        "import tempfile\n",
        "\n",
        "# Custom Libraries\n",
        "import Loading.load_data as ld\n",
        "import ImagePlayground.Images\n",
        "\n",
        "# Pytroch Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchmetrics\n",
        "\n",
        "# To Evaluate model\n",
        "from tqdm import tqdm\n",
        "import torchmetrics\n",
        "from torchmetrics import ConfusionMatrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# To visualize model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from skimage.io import imread\n",
        "\n",
        "# To split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdbry9Rg6Mvl"
      },
      "source": [
        "# also import keys for aws connection\n",
        "from gdrive.MyDrive.Colab_Notebooks.clocks_aws_config import clockss3\n",
        "pubkey = clockss3['accessCode']\n",
        "seckey = clockss3['secretCode']\n",
        "client = boto3.client('s3', aws_access_key_id=pubkey, aws_secret_access_key=seckey)\n",
        "#response = client.list_buckets()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5jwtXk7qv9-"
      },
      "source": [
        "# Build CNN Model using Pytorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nKizV2h4lMH"
      },
      "source": [
        "### Building and Training\n",
        "Architecture choices influenced from: \n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2018/12/guide-convolutional-neural-network-cnn/\n",
        "\n",
        "https://medium.datadriveninvestor.com/five-powerful-cnn-architectures-b939c9ddd57b\n",
        "\n",
        "https://towardsdatascience.com/how-does-sparse-convolution-work-3257a0a8fd1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OOYf4s0smrq"
      },
      "source": [
        "#epochs = 2\n",
        "train_batch_size = 8\n",
        "val_batch = 4\n",
        "test_batch = 1\n",
        "learning_rate = 1e-3\n",
        "kernel_size = 3\n",
        "stride = 1\n",
        "padding = 1 #2*floor(3/2)\n",
        "weight_decay = 1e-5\n",
        "# Define file extension to use for new data saves\n",
        "extension_ = \"res_netfp\"\n",
        "# Normalize data if rgb and set rgb_val to True to convert \n",
        "normalize_ = 'True'\n",
        "# Define which round to get data from\n",
        "rnd = 7\n",
        "# Define model extensions for naming file (which model do we want to train on)\n",
        "model_ext = \"3\"\n",
        "# m = 'First model'\n",
        "# m = 'pre-trained'\n",
        "#m = 'pre-trained-res'\n",
        "m = 'resnet'"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypf_eiS8Eghk"
      },
      "source": [
        "def open_dict(path):\n",
        "    \"\"\"Takes in path and opens file\"\"\"\n",
        "\n",
        "    cust_file = open(path, \"r\")\n",
        "    contents = cust_file.read()\n",
        "    dictionary = ast.literal_eval(contents)\n",
        "    cust_file.close()\n",
        "\n",
        "    return dictionary\n",
        "\n",
        "\n",
        "dictionarytr = open_dict(\n",
        "    \"/content/MADSmilestone2/Data/Dictionaries/score_dicts/tr_scor_dict_bal.txt\"\n",
        ")\n",
        "dictionaryv = open_dict(\n",
        "    \"/content/MADSmilestone2/Data/Dictionaries/score_dicts/val_scor_dict_nobal.txt\"\n",
        ")\n",
        "dictionaryts = open_dict(\n",
        "    \"/content/MADSmilestone2/Data/Dictionaries/score_dicts/tst_scor_dict_nobal.txt\"\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54Zv5Nsk-R-U",
        "outputId": "8dd10f4f-c1cb-43cc-de4c-76fb62cf8bc8"
      },
      "source": [
        "for id, val in dictionarytr.items():\n",
        "  print(\"Round {} length is {}\".format(str(id), str(len(val))))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 9 length is 1936\n",
            "Round 7 length is 2413\n",
            "Round 8 length is 2211\n",
            "Round 4 length is 1740\n",
            "Round 2 length is 2617\n",
            "Round 10 length is 1464\n",
            "Round 5 length is 3367\n",
            "Round 6 length is 2740\n",
            "Round 3 length is 1976\n",
            "Round 1 length is 3536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUo2KZ_UYhYE"
      },
      "source": [
        "class ResizedClocks:\n",
        "    # Resized clock drawing dataset\n",
        "\n",
        "    def __init__(self, round, round_labels, rgb=None, transform=None):\n",
        "\n",
        "        # Args:\n",
        "        # round (int): Round to grab images from.\n",
        "        # values (list of tuples): Corresponding values for the round.\n",
        "\n",
        "        self.round = round\n",
        "        self.vals = round_labels\n",
        "        self.client = boto3.client(\n",
        "            \"s3\", aws_access_key_id=pubkey, aws_secret_access_key=seckey\n",
        "        )\n",
        "        self.transform = transform\n",
        "        self.rgb = rgb\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.vals)\n",
        "\n",
        "    # def get_labels(self, idx):\n",
        "    # return self.vals[idx][1]#self.vals[:, 1]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        spid = self.vals[idx][0]\n",
        "        label = torch.tensor(int(self.vals[idx][1]))\n",
        "        bucket = \"clockimages\"  # \"test-bucket-clockids-aicrowd\"\n",
        "        obj_name = f\"NHATS_R{self.round}_ClockDrawings/{spid}.tif\"  # f\"{self.round}_{spid}.tif\"\n",
        "        # filename = str(spid)+\".tif\"\n",
        "        temp = tempfile.NamedTemporaryFile()\n",
        "\n",
        "        try:\n",
        "            client.download_file(bucket, obj_name, temp.name)  # filename)\n",
        "\n",
        "            im = Image.open(temp.name)  # filename)\n",
        "\n",
        "            if self.rgb:\n",
        "                #print('rgb')\n",
        "                gray = im.convert('RGB')\n",
        "            \n",
        "            else:\n",
        "                #print('gray')\n",
        "                gray = im.convert('1')\n",
        "\n",
        "            resized = gray.resize((160, 207))  # 284, 368))#(2560, 3312))\n",
        "            # resized = gray.resize((512, 662))\n",
        "            im_arr = np.float32(np.array(resized))  # .astype(float)\n",
        "\n",
        "            if self.transform:\n",
        "                im_arr = self.transform(im_arr)\n",
        "\n",
        "            # sample = {'image': im_arr, 'label': label}\n",
        "\n",
        "            temp.close()\n",
        "\n",
        "            return im_arr, label\n",
        "\n",
        "        except botocore.exceptions.ClientError as e:\n",
        "            return\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cco7mnKoYwEX"
      },
      "source": [
        "def collate_fn(batch):\n",
        "  \"\"\"From pytorch - way to bypass corrupt or non-existent data\"\"\"\n",
        "  batch = list(filter(lambda x: x is not None, batch))\n",
        "  return torch.utils.data.dataloader.default_collate(batch)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn8N9D4YZJcR"
      },
      "source": [
        "# initialize transformation: data to tensor and normalize\n",
        "# Could probably resize using torch.transforms\n",
        "if normalize_ == \"True\":\n",
        "    processes = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "    rgb_val = \"True\"\n",
        "else:\n",
        "    processes = transforms.ToTensor()\n",
        "    rgb_val = None\n",
        "    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz4e3izRZMJx"
      },
      "source": [
        "train_set = ResizedClocks(rnd, dictionarytr[rnd], transform = processes, rgb = rgb_val)\n",
        "val_set = ResizedClocks(rnd, dictionaryv[rnd], transform = processes, rgb = rgb_val)\n",
        "test_set = ResizedClocks(rnd, dictionaryts[rnd], transform = processes, rgb = rgb_val)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPc4Tg8yZPiE"
      },
      "source": [
        "# Define Dataloaders for the network\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = train_batch_size, shuffle = True, num_workers = 6, collate_fn=collate_fn) \n",
        "validate_loader = torch.utils.data.DataLoader(val_set, batch_size = val_batch, shuffle = True, num_workers = 6, collate_fn=collate_fn) #64, 8,1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kne45tSsQvFQ"
      },
      "source": [
        "# For round 10, there are some corrupt data that when batched at size 1 is not taken\n",
        "# care of by the collate function, but Nonechucks library skips the missing data and \n",
        "# moves on, replacing that missing data index with the next piece of data\n",
        "# could probably just use this in place of collate for all the loading\n",
        "if rnd == 10:\n",
        "  !pip install nonechucks\n",
        "  import nonechucks as nc\n",
        "  test_set_safe = nc.SafeDataset(test_set)\n",
        "  test_loader = torch.utils.data.DataLoader(test_set_safe, batch_size = test_batch, shuffle = False)\n",
        "else:\n",
        "  test_loader = torch.utils.data.DataLoader(test_set, batch_size = test_batch, shuffle = False, collate_fn=collate_fn)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAovKkRXFU4j"
      },
      "source": [
        "def set_model(m, model_ext, device):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"First Model training on GPU\")\n",
        "\n",
        "        if m == \"First model\":\n",
        "            # Create model object\n",
        "            model = ConvNet()\n",
        "            model = model.to(device)  # (float).cuda()\n",
        "\n",
        "        elif m == \"pre-trained\":\n",
        "            mPATH = \"/content/gdrive/MyDrive/Colab Notebooks/Models/cnn_512_662.model{}\".format(\n",
        "                model_ext\n",
        "            )\n",
        "            model = ConvNet()\n",
        "            model.load_state_dict(torch.load(mPATH))\n",
        "            model.to(device)\n",
        "            print(\"New Model{} training on GPU\".format(model_ext))\n",
        "\n",
        "        elif m == \"resnet\":\n",
        "            model = models.resnet50(pretrained=True)\n",
        "            num_ftrs = model.fc.in_features\n",
        "            model.fc = nn.Linear(num_ftrs, 6)\n",
        "            model = model.to(device)\n",
        "            print(\"RESNET Model training on GPU\")\n",
        "\n",
        "        elif m == \"pre-trained-res\":\n",
        "            mPATH = \"/content/gdrive/MyDrive/Colab Notebooks/Models/cnn_512_662.model{}\".format(\n",
        "                model_ext\n",
        "            )\n",
        "            model = models.resnet50()\n",
        "            num_ftrs = model.fc.in_features\n",
        "            model.fc = nn.Linear(num_ftrs, 6)\n",
        "            model.load_state_dict(torch.load(mPATH))\n",
        "            model.to(device)\n",
        "            print(\"New Model{} training on GPU\".format(model_ext))\n",
        "\n",
        "    else:\n",
        "        print(\"CUDA is not available. Turn on GPU\")\n",
        "\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiY5mGPbZxDV"
      },
      "source": [
        "def accuracy(y_pred, y_test):\n",
        "  # Calculating model accuracy at each epoch \n",
        "  y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "  _, y_pred_prob = torch.max(y_pred_softmax, dim = 1)\n",
        "  correct_pred = (y_pred_prob == y_test).float()\n",
        "  acc = correct_pred.sum() / len(correct_pred)\n",
        "  acc = torch.round(acc * 100)\n",
        "\n",
        "  return acc"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrUu9AXiZ0SL"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        # without considering batch size: Input shape : (None,368, 284, 1) , parameters: (3*3*1*16+16) = 160\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=16,  # one input channel gray scale, 16 filters out\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "        )  # Out:(None,386, 284, 16). ### TRY kernel 7x7 padding 3\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1\n",
        "        )  # params: (3*3*16*32+32) = 4640\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)  # Out: (None, 184, 142, 32)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1\n",
        "        )  # params: (3*3*16*32+32) = 4640\n",
        "        self.conv4 = nn.Conv2d(\n",
        "            in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
        "        )  # params: (3*3*32*32+32) = 9248\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # Output shape = (None, 92, 71, 64)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 128,\n",
        "        # kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248\n",
        "        self.conv6 = nn.Conv2d(\n",
        "            in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1\n",
        "        )  # params: (3*3*32*32+32) = 9248\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)  # Output shape = (None, 46, 35, 128)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.do2 = nn.Dropout(0.3)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc1 = nn.Linear(\n",
        "            128 * 64 * 82, 60\n",
        "        )  # most recent original size of: 512, 662 -->64 x 82\n",
        "        self.do3 = nn.Dropout(0.4)  # 40 % probability\n",
        "        # self.fc3 = nn.Linear(60, 30)\n",
        "        self.fc2 = nn.Linear(60, 6)  # left with 3 for the three classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))))\n",
        "        x = self.bn2(self.pool2(F.relu(self.conv4(F.relu(self.conv3(x))))))\n",
        "        # x = self.bn3(self.pool3(F.relu(self.conv6(F.relu(self.conv5(x))))))\n",
        "        x = self.bn3(self.pool3(F.relu(self.conv6((x)))))\n",
        "        x = self.do2(x)\n",
        "        x = x.view(x.size(0), 128 * 64 * 82)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.do3(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J29SCjraCcu"
      },
      "source": [
        "def train_val_model(epochs):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "\n",
        "        train_epoch_loss = 0\n",
        "        train_epoch_acc = 0\n",
        "\n",
        "        # set model in training mode\n",
        "        model.train()\n",
        "        print(\"\\nEpoch$ : %d\" % epoch)\n",
        "        for x_train_batch, y_train_batch in tqdm(train_loader):\n",
        "            x_train_batch = x_train_batch.to(\n",
        "                device\n",
        "            )  # (float).to(device) # for GPU support\n",
        "            y_train_batch = y_train_batch.to(device)\n",
        "\n",
        "            # print(x_train_batch.shape)\n",
        "\n",
        "            # sets gradients to 0 to prevent interference with previous epoch\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass through NN\n",
        "            y_train_pred = model(x_train_batch)  # .to(float)\n",
        "            train_loss = criterion(y_train_pred, y_train_batch)\n",
        "            train_acc = accuracy(y_train_pred, y_train_batch)\n",
        "\n",
        "            # Backward pass, updating weights\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            train_epoch_loss += train_loss.item()\n",
        "            train_epoch_acc += train_acc.item()\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            val_epoch_loss = 0\n",
        "            val_epoch_acc = 0\n",
        "\n",
        "            model.eval()\n",
        "            for x_val_batch, y_val_batch in tqdm(validate_loader):\n",
        "\n",
        "                x_val_batch = x_val_batch.to(device)  # .to(float)\n",
        "                y_val_batch = y_val_batch.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                y_val_pred = model(x_val_batch)  # .to(float)\n",
        "                val_loss = criterion(y_val_pred, y_val_batch)\n",
        "                val_acc = accuracy(y_val_pred, y_val_batch)\n",
        "\n",
        "                val_epoch_loss += val_loss.item()\n",
        "                val_epoch_acc += val_acc.item()\n",
        "\n",
        "        # Prevent plateauing validation loss\n",
        "        # scheduler.step(val_epoch_loss/len(validate_loader))\n",
        "\n",
        "        loss_stats[\"train\"].append(train_epoch_loss / len(train_loader))\n",
        "        loss_stats[\"val\"].append(val_epoch_loss / len(validate_loader))\n",
        "        accuracy_stats[\"train\"].append(train_epoch_acc / len(train_loader))\n",
        "        accuracy_stats[\"val\"].append(val_epoch_acc / len(validate_loader))\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch+0:03}: Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(validate_loader):.5f}\"\n",
        "        )\n",
        "        print(\n",
        "            f\"Train Acc: {train_epoch_acc/len(train_loader):.3f} | Val Acc: {val_epoch_acc/len(validate_loader):.3f}\"\n",
        "        )\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE2oVsUSZgbl"
      },
      "source": [
        " # Set to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFAXymkCZ8aX",
        "outputId": "40142c46-fea0-4b61-c9f3-a2fe7ccec9f7"
      },
      "source": [
        "# Get model\n",
        "model = set_model(m, model_ext, device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)#, momentum = 0.9) #or ADAM/ momentum\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
        ")\n",
        "\n",
        "# scheduler = lr_scheduler.StepLR(optimizer, step_size = 4, gamma=0.1)\n",
        "scheduler = ReduceLROnPlateau(optimizer, \"min\", patience=4)\n",
        "\n",
        "accuracy_stats = {\"train\": [], \"val\": []}\n",
        "\n",
        "loss_stats = {\"train\": [], \"val\": []}"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Model training on GPU\n",
            "RESNET Model training on GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5xpaSNBrNR5",
        "outputId": "8645e97d-65d1-4e15-d9b4-db2af0b157f1"
      },
      "source": [
        "train_val_model(15)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch$ : 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/302 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "100%|██████████| 302/302 [03:44<00:00,  1.34it/s]\n",
            "100%|██████████| 66/66 [00:27<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001: Train Loss: 1.52558 | Val Loss: 1.47334\n",
            "Train Acc: 38.623 | Val Acc: 34.848\n",
            "\n",
            "Epoch$ : 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:39<00:00,  1.37it/s]\n",
            "100%|██████████| 66/66 [00:26<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 002: Train Loss: 1.19244 | Val Loss: 1.30936\n",
            "Train Acc: 52.566 | Val Acc: 31.818\n",
            "\n",
            "Epoch$ : 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:41<00:00,  1.36it/s]\n",
            "100%|██████████| 66/66 [00:26<00:00,  2.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 003: Train Loss: 0.99775 | Val Loss: 1.27761\n",
            "Train Acc: 60.894 | Val Acc: 41.667\n",
            "\n",
            "Epoch$ : 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:41<00:00,  1.37it/s]\n",
            "100%|██████████| 66/66 [00:25<00:00,  2.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 004: Train Loss: 0.87355 | Val Loss: 1.30445\n",
            "Train Acc: 67.798 | Val Acc: 41.288\n",
            "\n",
            "Epoch$ : 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:46<00:00,  1.33it/s]\n",
            "100%|██████████| 66/66 [00:25<00:00,  2.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 005: Train Loss: 0.74368 | Val Loss: 1.31176\n",
            "Train Acc: 72.854 | Val Acc: 39.394\n",
            "\n",
            "Epoch$ : 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:35<00:00,  1.40it/s]\n",
            "100%|██████████| 66/66 [00:25<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 006: Train Loss: 0.61080 | Val Loss: 1.40530\n",
            "Train Acc: 78.132 | Val Acc: 42.803\n",
            "\n",
            "Epoch$ : 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:39<00:00,  1.38it/s]\n",
            "100%|██████████| 66/66 [00:25<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 007: Train Loss: 0.49876 | Val Loss: 1.33805\n",
            "Train Acc: 83.344 | Val Acc: 41.288\n",
            "\n",
            "Epoch$ : 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:39<00:00,  1.38it/s]\n",
            "100%|██████████| 66/66 [00:25<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 008: Train Loss: 0.39873 | Val Loss: 1.75923\n",
            "Train Acc: 87.805 | Val Acc: 31.818\n",
            "\n",
            "Epoch$ : 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:38<00:00,  1.38it/s]\n",
            "100%|██████████| 66/66 [00:25<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 009: Train Loss: 0.31482 | Val Loss: 1.57305\n",
            "Train Acc: 90.940 | Val Acc: 40.909\n",
            "\n",
            "Epoch$ : 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:37<00:00,  1.39it/s]\n",
            "100%|██████████| 66/66 [00:25<00:00,  2.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 010: Train Loss: 0.24307 | Val Loss: 1.76667\n",
            "Train Acc: 93.523 | Val Acc: 44.318\n",
            "\n",
            "Epoch$ : 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:38<00:00,  1.38it/s]\n",
            "100%|██████████| 66/66 [00:26<00:00,  2.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 011: Train Loss: 0.17972 | Val Loss: 2.19156\n",
            "Train Acc: 95.709 | Val Acc: 36.364\n",
            "\n",
            "Epoch$ : 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:38<00:00,  1.38it/s]\n",
            "100%|██████████| 66/66 [00:25<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 012: Train Loss: 0.14039 | Val Loss: 2.00478\n",
            "Train Acc: 96.500 | Val Acc: 44.697\n",
            "\n",
            "Epoch$ : 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:37<00:00,  1.39it/s]\n",
            "100%|██████████| 66/66 [00:25<00:00,  2.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 013: Train Loss: 0.13652 | Val Loss: 1.96838\n",
            "Train Acc: 96.377 | Val Acc: 45.076\n",
            "\n",
            "Epoch$ : 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:40<00:00,  1.37it/s]\n",
            "100%|██████████| 66/66 [00:25<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 014: Train Loss: 0.10357 | Val Loss: 1.92887\n",
            "Train Acc: 97.589 | Val Acc: 46.970\n",
            "\n",
            "Epoch$ : 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 302/302 [03:35<00:00,  1.40it/s]\n",
            "100%|██████████| 66/66 [00:26<00:00,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 015: Train Loss: 0.10073 | Val Loss: 2.08656\n",
            "Train Acc: 97.914 | Val Acc: 41.667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SunqC9OGaO_r"
      },
      "source": [
        "# added learning rate decay after 3rd epoch\n",
        "# 1st: round 1\n",
        "# 2nd: round 5\n",
        "# 3rd: round 6 best so far\n",
        "# 4th: round 7\n",
        "# 5th (model) saved training on 9\n",
        "# 6th: round 2\n",
        "# 7th round 8\n",
        "# 8th round 3\n",
        "# 9th round 4\n",
        "# 10th round 10"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHUjtLim2mdN"
      },
      "source": [
        "# Visualize the Training and Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv3SoFHj2ssM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "1c68d43f-5bb7-4dc5-fdbb-1c58517840ea"
      },
      "source": [
        "# Create dataframes\n",
        "train_val_acc_df = pd.DataFrame.from_dict(accuracy_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
        "train_val_loss_df = pd.DataFrame.from_dict(loss_stats).reset_index().melt(id_vars=['index']).rename(columns={\"index\":\"epochs\"})\n",
        "train_val_acc_df.to_csv('/content/gdrive/MyDrive/Colab Notebooks/acc_loss/acc{}.csv'.format(extension_), index = False)\n",
        "train_val_loss_df.to_csv('/content/gdrive/MyDrive/Colab Notebooks/acc_loss/loss{}.csv'.format(extension_), index = False)\n",
        "# Plot the dataframes\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,7))\n",
        "sns.lineplot(data=train_val_acc_df, x = \"epochs\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Train-Val Accuracy/Epoch')\n",
        "sns.lineplot(data=train_val_loss_df, x = \"epochs\", y=\"value\", hue=\"variable\", ax=axes[1]).set_title('Train-Val Loss/Epoch')\n",
        "fig.savefig('/content/gdrive/MyDrive/Colab Notebooks/model_charts/acc_loss{}.png'.format(extension_))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-228b95fd48e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_val_acc_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_val_loss_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_val_acc_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/Colab Notebooks/acc_loss/acc{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextension_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain_val_loss_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/Colab Notebooks/acc_loss/loss{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextension_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Plot the dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m         )\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             )\n\u001b[1;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/Colab Notebooks/acc_loss/acc4_fix.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITYjyxcK2a9P"
      },
      "source": [
        "# Evaluate the model using Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxkr2sXqqy6x"
      },
      "source": [
        "# Calculate performance\n",
        "y_test = torch.tensor([])\n",
        "test_acc = torchmetrics.Accuracy()\n",
        "\n",
        "with torch.set_grad_enabled(False):\n",
        "  model.eval()\n",
        "  #model.to(float)\n",
        "  for batches in tqdm(test_loader):\n",
        "    x_test, y_test = batches\n",
        "    x_test = x_test.to(device)\n",
        "    y_test = y_test.to(device)\n",
        "    y_pred = model(x_test)\n",
        "    test_acc(y_pred.cpu(), y_test.cpu())\n",
        "    total_test_acc = test_acc.compute()\n",
        "  print('test acc: ', total_test_acc)\n",
        "  test_acc.reset()\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4OOWwEWrW2-"
      },
      "source": [
        "## Create Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QROmDemn_QeY"
      },
      "source": [
        "all_pred = []\n",
        "all_preds = torch.tensor([])\n",
        "y_test = torch.tensor([])\n",
        "with torch.set_grad_enabled(False):\n",
        "  model.eval()\n",
        "  for x_test_batch, y_test_batch in tqdm(test_loader):\n",
        "    x_test_batch = x_test_batch.to(device)#.to(float).to(device)\n",
        "    y_test_pred = model(x_test_batch)\n",
        "    _, y_pred_probs = torch.max(y_test_pred, dim = 1)\n",
        "    all_pred.append(y_pred_probs.cpu().numpy())\n",
        "    all_preds = torch.cat((all_preds.cpu(), y_pred_probs.cpu()),dim = 0)\n",
        "    y_test = torch.cat((y_test, y_test_batch), dim = 0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI5PGwvU_SZq"
      },
      "source": [
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_test, all_pred))#.rename(columns=idx2class, index=idx2class)\n",
        "sns.heatmap(confusion_matrix_df, annot=True, fmt=\".2f\", cmap='BuGn')\n",
        "plt.xlabel(\"prediction\")\n",
        "plt.ylabel(\"label (ground truth)\")\n",
        "plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/model_charts/CMTX{}.png'.format(extension_))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqMBs_YS_U0U"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "#class_names = [\"Possible Dementia\", \"Likely Dementia\", \"No Dementia\"]\n",
        "class_vals = [0,1,2]\n",
        "\n",
        "cr = classification_report(y_test, all_pred, class_vals, output_dict = True)\n",
        "try:\n",
        "    cr_file = open('/content/gdrive/MyDrive/Colab Notebooks/model_charts/cr{}.txt'.format(extension_), 'wt')\n",
        "    cr_file.write(str(cr))\n",
        "    cr_file.close()\n",
        "  \n",
        "except:\n",
        "    print(\"Unable to write to file\")\n",
        "print(classification_report(y_test, all_pred, class_vals))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhz6gXGHpcMB"
      },
      "source": [
        "# Plot ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nQrbRJ9_Xoh"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "\n",
        "target= [0, 1, 2]\n",
        "\n",
        "# set plot figure size\n",
        "fig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n",
        "\n",
        "# function for scoring roc auc score for multi-class\n",
        "def multiclass_roc_auc_score(y_test1, all_pred1, average=\"macro\"):\n",
        "    lb = LabelBinarizer()\n",
        "    lb.fit(y_test1)\n",
        "    y_test1 = lb.transform(y_test1)\n",
        "    all_pred1 = lb.transform(all_pred1)\n",
        "\n",
        "    for (idx, c_label) in enumerate(target):\n",
        "        fpr, tpr, thresholds = roc_curve(y_test1[:,idx].astype(int), all_pred1[:,idx])\n",
        "        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
        "    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n",
        "    return roc_auc_score(y_test1, all_pred1, average=average)\n",
        "\n",
        "\n",
        "print('ROC AUC score:', multiclass_roc_auc_score(y_test, all_pred))\n",
        "\n",
        "c_ax.legend()\n",
        "c_ax.set_xlabel('False Positive Rate')\n",
        "c_ax.set_ylabel('True Positive Rate')\n",
        "plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/model_charts/roc{}.png'.format(extension_))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8DS8yc9YMQg"
      },
      "source": [
        "# precision recall curve\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "\n",
        "# Use label_binarize to be multi-label like settings\n",
        "y = y_test.numpy()\n",
        "Y = label_binarize(y, classes=[0, 1, 2])\n",
        "Y_pred = label_binarize(all_pred, classes=[0, 1, 2])\n",
        "n_classes = Y.shape[1]\n",
        "\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "for i in range(n_classes):\n",
        "    precision[i], recall[i], _ = precision_recall_curve(Y[:, i],\n",
        "                                                        Y_pred[:, i])\n",
        "    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
        "    \n",
        "plt.xlabel(\"recall\")\n",
        "plt.ylabel(\"precision\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.title(\"precision vs. recall curve\")\n",
        "plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/model_charts/auc_pr{}.png'.format(extension_))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKR_i_oebCi2"
      },
      "source": [
        "## Save the GPU CNN Model\n",
        "Also includes loading on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTEwjKcbbAlJ"
      },
      "source": [
        "# Save GPU model\n",
        "model_name = 'cnn_1run.model{}'.format(extension_)\n",
        "PATH = \"/content/gdrive/MyDrive/Colab_Notebooks/{}\".format(model_name)\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm-xL-D6bcp6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9aa7f8ab-ca41-41ec-b167-353f3d7a1a20"
      },
      "source": [
        "\"\"\"# Load GPU model\n",
        "device = torch.device(\"cuda\")\n",
        "model = TheModelClass(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.to(device)\"\"\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'# Load GPU model\\ndevice = torch.device(\"cuda\")\\nmodel = TheModelClass(*args, **kwargs)\\nmodel.load_state_dict(torch.load(PATH))\\nmodel.to(device)'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z8UDiRbLUG8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "64de57f0-cc6c-489e-f0f2-1a0c328bf545"
      },
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    class_names = [0,1,2]\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(validate_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j].squeeze().permute(2,1))# image1.squeeze().permute(1,2,0)\n",
        "                #imshow(np.transpose(inputs.cpu().data[j], (2, 0, 1)))\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "visualize_model(model)  "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c64182e37b4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwas_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mvisualize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-c64182e37b4b>\u001b[0m in \u001b[0;36mvisualize_model\u001b[0;34m(model, num_images)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_so_far\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# image1.squeeze().permute(1,2,0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;31m#imshow(np.transpose(inputs.cpu().data[j], (2, 0, 1)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKYAAABOCAYAAACqn22YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAA6klEQVR4nO3SMQEAIAzAMMC/52GAnx6Jgh7dM7Og5vwOgBdjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJMiZJxiTJmCQZkyRjkmRMkoxJkjFJuiISA5nXU27HAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhrsllHHYf9H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}