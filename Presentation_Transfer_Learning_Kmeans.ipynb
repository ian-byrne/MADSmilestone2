{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Presentation_Transfer Learning Kmeans.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP0GZ1EY20rkKSnYXIfPmjh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ian-byrne/MADSmilestone2/blob/main/Presentation_Transfer_Learning_Kmeans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRmz38QaqNcd"
      },
      "source": [
        "# Transfer Learning and applying PCA to K-Means\n",
        "\n",
        "- Requires Google Colab Pro Plus. 'High-RAM' of 51GB setting to be set\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bkxj5ev_zKj",
        "outputId": "d12e5c2b-09bd-470a-dda1-00857616c6f6"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/ian-byrne/MADSmilestone2.git\n",
        "\n",
        "# Change directory into cloned repo\n",
        "%cd MADSmilestone2\n",
        "\n",
        "# List repo contents\n",
        "!ls"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MADSmilestone2'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 805, done.\u001b[K\n",
            "remote: Counting objects: 100% (805/805), done.\u001b[K\n",
            "remote: Compressing objects: 100% (677/677), done.\u001b[K\n",
            "remote: Total 805 (delta 435), reused 272 (delta 118), pack-reused 0\n",
            "Receiving objects: 100% (805/805), 7.83 MiB | 7.87 MiB/s, done.\n",
            "Resolving deltas: 100% (435/435), done.\n",
            "/content/MADSmilestone2/MADSmilestone2\n",
            "Analysis.ipynb\t\tpresentation_CNN2_scores.ipynb\n",
            "CNN2_scores.ipynb\tpresentation_Supervised_CNN.ipynb\n",
            "Data\t\t\tPresentation_Transfer_Learning_Kmeans.ipynb\n",
            "dataloader_tests.ipynb\tproj_models.py\n",
            "ImagePlayground\t\tREADME.md\n",
            "Labeling\t\tscores_cnn_resnet.ipynb\n",
            "Loading\t\t\tSupervised_CNN.ipynb\n",
            "Model_Datasets.ipynb\tTransfer_Learning_Kmeans.ipynb\n",
            "multimodel1.ipynb\tutils.py\n",
            "multimodel2.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlOtXXtK8so8"
      },
      "source": [
        "!pip install boto3 torchmetrics\n",
        "\n",
        "\n",
        "# Pytroch Libraries\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchmetrics\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Other Libraries\n",
        "import botocore\n",
        "import tempfile\n",
        "from tqdm import tqdm\n",
        "import boto3\n",
        "import io\n",
        "import os\n",
        "import ast\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "\n",
        "# Sklearn libraries\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from scipy.stats import mode\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "# Custom Libraries\n",
        "import Loading.load_data as ld\n",
        "from utils import open_dict\n",
        "from proj_models import ResizedClocks\n",
        "from utils import collate_fn\n",
        "from utils import set_model\n",
        "from utils import accuracy\n",
        "from proj_models import ConvNet\n",
        "from utils import train_val_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QsWRQUX6IeJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "384a42e1-9a6f-4dae-e040-d6f448aa601f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJg73_9odYlp"
      },
      "source": [
        "# also import keys for aws connection\n",
        "from gdrive.MyDrive.Colab_Notebooks.clocks_aws_config import clockss3\n",
        "pubkey = clockss3['accessCode']\n",
        "seckey = clockss3['secretCode']\n",
        "client = boto3.client('s3', aws_access_key_id=pubkey, aws_secret_access_key=seckey)\n",
        "#response = client.list_buckets()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a587eJhXj6AN"
      },
      "source": [
        "path = '/content/MADSmilestone2/Data/Dictionaries/dementia_label_dicts/train_dict_nhat.txt'\n",
        "cust_file = open(path, \"r\")\n",
        "#print(cust_file.readline())\n",
        "contents = cust_file.read() \n",
        "dictionarytr = ast.literal_eval(contents)\n",
        "cust_file.close()\n",
        "\n",
        "path1 = '/content/MADSmilestone2/Data/Dictionaries/dementia_label_dicts/val_dict_nhat.txt'\n",
        "cust_file = open(path1, \"r\")\n",
        "#print(cust_file.readline())\n",
        "contents = cust_file.read()\n",
        "dictionaryv = ast.literal_eval(contents)\n",
        "cust_file.close()\n",
        "\n",
        "path2 = '/content/MADSmilestone2/Data/Dictionaries/dementia_label_dicts/test_dict_nhat.txt'\n",
        "cust_file = open(path2, \"r\")\n",
        "#print(cust_file.readline())\n",
        "contents = cust_file.read()\n",
        "dictionaryts = ast.literal_eval(contents)\n",
        "cust_file.close()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbMI4s9hk5QE"
      },
      "source": [
        "# Define some of the loader variables\n",
        "train_batch_size = 1\n",
        "val_batch = 4\n",
        "test_batch = 1\n",
        "rnd = 7\n",
        "normalize_ = True\n",
        "\n",
        "# Set to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# set model parameters to choose model for extracting features\n",
        "m = 'res50'# 'conv'\n",
        "model_ext = '4_fix'"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAj2BS4Xnkm9"
      },
      "source": [
        "train_set = ResizedClocks(rnd, dictionarytr[rnd], pubkey, seckey, normalize_=True)\n",
        "val_set = ResizedClocks(rnd, dictionaryv[rnd], pubkey, seckey, normalize_=True)\n",
        "test_set = ResizedClocks(rnd, dictionaryts[rnd], pubkey, seckey, normalize_=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_l6UFWDnqw6"
      },
      "source": [
        "# Define Dataloaders for the network\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = train_batch_size, shuffle = True, num_workers = 6, collate_fn=collate_fn) \n",
        "validate_loader = torch.utils.data.DataLoader(val_set, batch_size = val_batch, shuffle = True, num_workers = 6, collate_fn=collate_fn) #64, 8,1"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCrPRAyynrMy"
      },
      "source": [
        "# For round 10, there are some corrupt data that when batched at size 1 is not taken\n",
        "# care of by the collate function, but Nonechucks library skips the missing data and \n",
        "# moves on, replacing that missing data index with the next piece of data\n",
        "# could probably just use this in place of collate for all the loading\n",
        "if rnd == 10:\n",
        "  !pip install nonechucks\n",
        "  import nonechucks as nc\n",
        "  test_set_safe = nc.SafeDataset(test_set)\n",
        "  test_loader = torch.utils.data.DataLoader(test_set_safe, batch_size = test_batch, shuffle = False)\n",
        "else:\n",
        "  test_loader = torch.utils.data.DataLoader(test_set, batch_size = test_batch, shuffle = False, collate_fn=collate_fn)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhrEvCuYrXAZ",
        "outputId": "8d331614-93be-411a-9a46-329a8bb835e8"
      },
      "source": [
        "# Get model\n",
        "if m == 'conv':\n",
        "  model_ext = '4_fix'\n",
        "  mPATH = '/content/gdrive/MyDrive/Colab Notebooks/Models/cnn_512_662.model{}'.format(model_ext)\n",
        "  model = ConvNet()\n",
        "  #model.load_state_dict(torch.load(mPATH, map_location=torch.device('cpu')))\n",
        "  model.load_state_dict(torch.load(mPATH))\n",
        "  model.to(device)\n",
        "  print(\"conv\")\n",
        "\n",
        "if m == 'res50':\n",
        "  model = models.resnet50(pretrained = True)\n",
        "  num_ftrs = model.fc.in_features\n",
        "  model.fc = nn.Linear(num_ftrs, 3)\n",
        "  model = model.to(device)\n",
        "  print(\"res 50 pretrained\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "res 50 pretrained\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6m6xdD8plDQ"
      },
      "source": [
        "#original size: 2560, 3312\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    \n",
        "    # without considering batch size: Input shape : (None,368, 284, 1) , parameters: (3*3*1*16+16) = 160\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 16, # one input channel gray scale, 16 filters out\n",
        "                            kernel_size = 3, stride = 1, padding = 1) #Out:(None,386, 284, 16). ### TRY kernel 7x7 padding 3\n",
        "    self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) #params: (3*3*16*32+32) = 4640                        \n",
        "    self.pool1 = nn.MaxPool2d(2, 2) #Out: (None, 184, 142, 32) \n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) #params: (3*3*16*32+32) = 4640    \n",
        "    self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 64, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248                    \n",
        "    self.pool2 = nn.MaxPool2d(2, 2) #Output shape = (None, 92, 71, 64) \n",
        "    self.bn2 = nn.BatchNorm2d(64)  \n",
        "\n",
        "    #self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 128, \n",
        "                          #kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248 \n",
        "    self.conv6 = nn.Conv2d(in_channels = 64, out_channels = 128, \n",
        "                          kernel_size = 3, stride = 1, padding = 1) # params: (3*3*32*32+32) = 9248\n",
        "    self.pool3 = nn.MaxPool2d(2, 2) #Output shape = (None, 46, 35, 128) \n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "    self.do2 = nn.Dropout(0.3)\n",
        "                                   \n",
        "                             \n",
        "    # Fully connected layer\n",
        "    self.fc1 = nn.Linear(128*64*82,60) #most recent original size of: 512, 662 -->64 x 82\n",
        "    self.do3 = nn.Dropout(0.4) #40 % probability  \n",
        "    #self.fc3 = nn.Linear(60, 30)\n",
        "    self.fc2 = nn.Linear(60, 3) # left with 3 for the three classes                     \n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn1(self.pool1(F.relu(self.conv2(F.relu(self.conv1(x))))))\n",
        "    x = self.bn2(self.pool2(F.relu(self.conv4(F.relu(self.conv3(x))))))\n",
        "    #x = self.bn3(self.pool3(F.relu(self.conv6(F.relu(self.conv5(x))))))\n",
        "    x = self.bn3(self.pool3(F.relu(self.conv6((x)))))\n",
        "    x = self.do2(x)\n",
        "    x = x.view(x.size(0),128*64*82)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.do3(x)\n",
        "    x = self.fc2(x)\n",
        "    return x              "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rAWdxiWkyyU"
      },
      "source": [
        "# Transfer Learning with PCA and K-Means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w5Y1KDj3dz2"
      },
      "source": [
        "### Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij-c1MqHAFzc"
      },
      "source": [
        "# Remove prediction layer (last fc layer)\n",
        "if m == 'res50':\n",
        "  model_1 = nn.Sequential(*list(model.children())[:-1])\n",
        "else:\n",
        "  model_1 = nn.Sequential(*list(model.children())[:-3]) # removes last FCs of CNN"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPSmio_aA2RF"
      },
      "source": [
        "# Use model for evaluation\n",
        "model_1.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GDqbInOVXbO"
      },
      "source": [
        "# Hold the data sets\n",
        "X = []\n",
        "y_train=[]\n",
        "for x, lb in tqdm(test_loader):\n",
        "  print(x.size)\n",
        "  # Get image features from model\n",
        "  x = x.to(device)\n",
        "  preds = model_1(x)\n",
        "  X.append(preds.cpu())\n",
        "  y_train.append(lb)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCrc8SzhOZXL"
      },
      "source": [
        "print(\"Shape of Tensor Array X: \", X[0].shape)\n",
        "x_ = np.array([t.cpu().detach().numpy() for t in X])\n",
        "print(\"Shape of Numpy Array X: \", x_.shape)\n",
        "y_train_ = np.array(y_train)\n",
        "print(\"Shape of y: \", (y_train_).shape)\n",
        "print(\"Type of y: \", type(y_train_))\n",
        "w = x_.reshape(x_.shape[0], -1)\n",
        "print(\"Shape of reshaped numpy array X: \", w.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYgzyqc33hee"
      },
      "source": [
        "### Perform PCA on data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEf9iFTxSaJK"
      },
      "source": [
        "def run_pca(w):\n",
        "  # Instantite PCA model\n",
        "  variance = 0.98 #The higher the variance the more accurate, more dimensions remain\n",
        "  pca = PCA(variance)\n",
        "\n",
        "  pca.fit(w) #fit the data \n",
        "  print(\"Number of components before PCA: \", w.shape[1])\n",
        "  print(\"Number of components after PCA {}:\".format(variance), pca.n_components_)\n",
        "\n",
        "  # Transform into new features\n",
        "  w_pca = pca.transform(w)\n",
        "  print(\"Dim after PCA: \", w_pca.shape)\n",
        "  return w_pca\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYK243KP3pAz"
      },
      "source": [
        "### Predict number of clusters using KMeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZB7kHJKPc1J"
      },
      "source": [
        "sil_score = []\n",
        "k_vals = []\n",
        "cost =[]\n",
        "k_max = 9\n",
        "\n",
        "# Get reduced features\n",
        "w_pca = run_pca(w)\n",
        "\n",
        "for k in range(2, k_max + 1):\n",
        "  kmeans1 = KMeans(n_clusters = k).fit(w_pca)#w)\n",
        "  labels = kmeans1.labels_\n",
        "  sil_score.append(silhouette_score(w_pca, labels, metric = 'euclidean'))\n",
        "  k_vals.append(k)\n",
        "\n",
        "for k in range(1, k_max + 2):\n",
        "  kmeans2 = KMeans(n_clusters = k, max_iter = 500).fit(w_pca)\n",
        "  # calculates squared error\n",
        "  # for the clustered points\n",
        "  cost.append(kmeans2.inertia_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-VjHtnh4qOD"
      },
      "source": [
        "Plot the Silhouette Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YyDD2knPkOb"
      },
      "source": [
        "#sil_name = '50res_fit7_hatsil.png'\n",
        "plt.plot(k_vals, sil_score)\n",
        "plt.ylabel('Silhoutte Score')\n",
        "plt.xlabel('Best K')\n",
        "plt.title('PCA dim from 2048 to 114')\n",
        "#plt.title('fit to round 7')\n",
        "plt.suptitle('ResNet pretrained on ImageNet')\n",
        "#plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/model_charts/{}'.format(sil_name))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzY_S27l4yj-"
      },
      "source": [
        "Plot the Elbow Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFpVZ2Gv4x_m"
      },
      "source": [
        "#elb_name = '50res_7_hatelb.png'\n",
        "\n",
        "# plot the cost against K values\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.plot(range(1, k_max + 2), cost, color ='g', linewidth ='3')\n",
        "plt.title('PCA dim from 2048 to 114')\n",
        "#plt.title('fit to round 7')\n",
        "plt.suptitle('Elbow Curve of Pretrained ResNet (ImageNet)')\n",
        "plt.xlabel(\"K value\")\n",
        "plt.ylabel(\"Squared Error\")\n",
        "\n",
        "#plt.savefig('/content/gdrive/MyDrive/Colab Notebooks/model_charts/{}'.format(elb_name))\n",
        "\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiIZUsepvvsY"
      },
      "source": [
        "# Apply optimal K with clustering for labeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IujNYx435Za"
      },
      "source": [
        "# Fit Reduced feature data to 3 clusters and predict classes\n",
        "kmeans = KMeans(n_clusters = 3, random_state = 0).fit(w_pca)\n",
        "clusters = kmeans.fit_predict(w_pca)\n",
        "print(\"cluster center shape: \", kmeans.cluster_centers_.shape)\n",
        "print(\"label shape: \", kmeans.labels_.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhFPtc1C62gG"
      },
      "source": [
        "raw_data = False\n",
        "if raw_data == True:\n",
        "  if m == 'res50':\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(9, 11))\n",
        "    centers = kmeans.cluster_centers_.reshape(3, 368, 284, 3)\n",
        "    for axi, center in zip(ax.flat, centers):\n",
        "        axi.set(xticks=[], yticks=[])\n",
        "        axi.imshow(center*255, interpolation='nearest', cmap=plt.cm.binary)\n",
        "  else:\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(9, 11))\n",
        "    centers = kmeans.cluster_centers_.reshape(3, 368, 284)\n",
        "    for axi, center in zip(ax.flat, centers):\n",
        "        axi.set(xticks=[], yticks=[])\n",
        "        axi.imshow(center, interpolation='nearest', cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgLiUoPb9zls"
      },
      "source": [
        "Calculate Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELUOXu6j-Hed"
      },
      "source": [
        "labels = np.zeros_like(kmeans.labels_)\n",
        "for i in range(3):\n",
        "    mask = (kmeans.labels_ == i)\n",
        "    #print(mask)\n",
        "    labels[mask] = mode(y_train_[mask])[0]\n",
        "\n",
        "\n",
        "accuracy_score(y_train_, labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvTj5KnVvAUE"
      },
      "source": [
        "matrix = confusion_matrix(y_train_, labels)\n",
        "sns.heatmap(matrix, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=[0,1,2],\n",
        "            yticklabels=[0,1,2])\n",
        "plt.ylabel('true label')\n",
        "plt.xlabel('predicted label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guv2Y8RcAP5U"
      },
      "source": [
        "Using NHATS label for round 7 un-balanced test set data, fit on Pretrained ReNet50 on ImageNet only using 3 clusters was 79% accurate compared to cluster labels. This set is unbalanced and is over-predicting the most common class. \n",
        "\n",
        "When used on the train_set, which is balanced, the accuracy plummets to ~34%\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyZdygGkFIjT"
      },
      "source": [
        "#y_pred = kmeans.predict(X_train)\n",
        "fig = plt.figure(figsize = (15,15))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "plt.scatter(X_train[clusters == 0,0],X_train[clusters == 0,1],s = 50, c = 'green', label = \"cluster 1\")\n",
        "plt.scatter(X_train[clusters == 1,0],X_train[clusters == 1,1],s = 50, c = 'blue', label = \"cluster 2\")\n",
        "plt.scatter(X_train[clusters == 2,0],X_train[clusters == 2,1],s = 50, c = 'pink', label = \"cluster 3\")\n",
        "plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1], s = 100, c = \"red\", label = \"centroids\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTOiHVDpQplH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}